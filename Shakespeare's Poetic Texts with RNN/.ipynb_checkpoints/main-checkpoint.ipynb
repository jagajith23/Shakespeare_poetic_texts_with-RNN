{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d1caf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jagaj\\anaconda3\\envs\\myenv\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\jagaj\\anaconda3\\envs\\myenv\\lib\\site-packages\\numpy\\.libs\\libopenblas.QVLO2T66WEPI7JZ63PS3HMOHFEY472BC.gfortran-win_amd64.dll\n",
      "C:\\Users\\jagaj\\anaconda3\\envs\\myenv\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np #make sure you have numpy version <= 1.19.3\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.models import load_model\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a96a769c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training with filepath1 gives shakespeare plays as output\n",
    "# filepath1 = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "\n",
    "# training with filepath2 gives shakespeare sonnets as output, I will upload the file in this repository\n",
    "filepath2 = 'shakespeare_sonnets.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a078cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(filepath2, 'rb').read().decode(encoding='utf-8').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a96e6933",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14dc069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_idx = dict((c, i) for i, c in enumerate(characters))\n",
    "idx_to_char = dict((i, c) for i, c in enumerate(characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fffd34e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "next_character = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8286b226",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LEN = 40\n",
    "STEP_SIZE = 3\n",
    "\n",
    "for i in range(0, len(text)-SEQUENCE_LEN, STEP_SIZE):\n",
    "    sentences.append(text[i: i+SEQUENCE_LEN])\n",
    "    next_character.append(text[i+SEQUENCE_LEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "792b40de",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((len(sentences), SEQUENCE_LEN, len(characters)), dtype=bool)\n",
    "y = np.zeros((len(sentences), len(characters)), dtype=bool)\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for j, character in enumerate(sentence):\n",
    "        x[i, j, char_to_idx[character]] = 1\n",
    "    y[i, char_to_idx[next_character[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be2f5117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "123/123 [==============================] - 10s 19ms/step - loss: 2.5896\n",
      "Epoch 2/4\n",
      "123/123 [==============================] - 2s 17ms/step - loss: 2.0667: 1s - loss: \n",
      "Epoch 3/4\n",
      "123/123 [==============================] - 2s 16ms/step - loss: 1.8870\n",
      "Epoch 4/4\n",
      "123/123 [==============================] - 1s 12ms/step - loss: 1.7519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: poetic_sonnet_text_generator.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: poetic_sonnet_text_generator.model\\assets\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(SEQUENCE_LEN, len(characters))))\n",
    "model.add(Dense(len(characters)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01))\n",
    "\n",
    "model.fit(x, y, batch_size=256, epochs=4)\n",
    "\n",
    "model.save('poetic_sonnet_text_generator.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af2340bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedModel1 = load_model('poetic_sonnet_text_generator.model')\n",
    "savedModel2 = load_model('poetic_text_generator.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "578a84b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1de080cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(length=400, temperature=0.6):\n",
    "    SEQUENCE_LEN = 40\n",
    "    STEP_SIZE = 3\n",
    "    generated = ''\n",
    "    user_input = input(\"Your input is: \").lower()\n",
    "    sentence = user_input.rjust(40, '0')\n",
    "    generated += user_input\n",
    "    \n",
    "    sys.stdout.write(\"\\nHere is your poetic texts: \\n\")\n",
    "    sys.stdout.write(user_input)\n",
    "    \n",
    "    for i in range(length):\n",
    "        x_pred = np.zeros((1, SEQUENCE_LEN, len(characters)))\n",
    "        \n",
    "        for t, character in enumerate(sentence):\n",
    "            if character != '0':\n",
    "                x_pred[0, t, char_to_idx[character]] = 1\n",
    "            \n",
    "        predictions = savedModel1.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(predictions, temperature)\n",
    "        next_character = idx_to_char[next_index]\n",
    "        \n",
    "        generated += next_character\n",
    "        sentence = sentence[1:] + next_character\n",
    "        \n",
    "        sys.stdout.write(next_character)\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        if next_character == '\\n':\n",
    "            continue        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b90a1189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your input is: Forsooth this maketh no sense\n",
      "\n",
      "Here is your poetic texts: \n",
      "forsooth this maketh no sense thee shine and me same,\n",
      "and i swain the bat facher a world mine neart be that as dith,\n",
      "and chan the pack she the thou that i beart my love a doth,\n",
      "and the lives a \n",
      "all the shart prome i  o shall so chandere.\n",
      "hath mine a dand the love that i have renow sime.\n",
      "and the sear the falling stime shes and your when is that thus be the though with mend,\n",
      "canless my live thou thou thow sam with shall life a "
     ]
    }
   ],
   "source": [
    "generate_text()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
